{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNea9/RbLPOPfhnET26rtFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manideep-malyala/gen-ai-exp/blob/main/RAG_Ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langchain-community sentence-transformers faiss-gpu pypdf langchain-ollama colab-xterm\n",
        "%load_ext colabxterm\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "hOuKOEUNq4Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temp cell for terminal connection : triggering commands : starting ollama server\n",
        "%xterm"
      ],
      "metadata": {
        "id": "LFP2e-IaH1YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull gemma2:2b > /dev/null 2>&1\n",
        "!ollama list"
      ],
      "metadata": {
        "id": "rhDfay88I3eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.llms import Ollama\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "-ngciL8Ir6WY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path =r\"/content/rs_paper.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(file_path)\n",
        "pages = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\\n\")\n",
        "documents = text_splitter.split_documents(documents = pages)"
      ],
      "metadata": {
        "id": "1UHfPS67tJmn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "embed_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "    model_kwargs=model_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "EbMXELMX1EbF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = FAISS.from_documents(documents, embedding_model)\n",
        "vector_store.save_local(\"faiss_index\")\n",
        "persistant_vector_store = FAISS.load_local(\"faiss_index\", embedding_model)\n",
        "retriever = persistant_vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "zop9W2Ly11Kb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Ollama(model=\"gemma2:2b\")"
      ],
      "metadata": {
        "id": "eHMiBN7-6kB-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "user_query = input(\"Query : \")\n",
        "ai_response = qa({\"query\": user_query})\n",
        "\n",
        "print(60*\"_\")\n",
        "\n",
        "print(\"\\nAI Response  :\\n\")\n",
        "display(Markdown(ai_response['result']))\n",
        "\n",
        "print(60*\"_\")\n",
        "\n",
        "print(\"\\nReference  :\\n\")\n",
        "for source in ai_response[\"source_documents\"]:\n",
        "    print(source.metadata)\n"
      ],
      "metadata": {
        "id": "GR2D4uVz-dF3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}